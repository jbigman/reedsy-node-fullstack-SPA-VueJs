# A-PLAN : Use git versionning system

Git allows 
- [x] show the novel in its current state
- [x] show the novel at any point in its history
- [x] show the changes made between two versions
- [x] prioritize disk space efficiency
- [ ] discuss any trade-offs made, as well as potential mitigations
- [ ] consider any potential domain-specific issues
  
- no support for multi user access control
> Use read only branches for readers (no rights to push)
- no support for real-time
> It would be needed to implement something to periodically pull repo and notify users if there is changes.
- technical complexity with commands and conflicts while doing git merge
> Force users to rebase periodically to avoid conflic as much as possible

- Usage not optimized for large text files (>100Mo)
> For disk efficiency it would be needed to archive only major versions.

# B-PLAN for Reedsy

My first instinct is to explore the best practices to adopt. I would do researches throught articles or AI to retrieve best practices to develop my own versionning and ensure that the versionning system architecture/design will fit domain-specific issues.

With more time i would have made researches on how git or other versioning system are working to copy what's good in their solutions. 

But to answer quickly in this exercise, i mainly used AI tools to build something solid for reedsy context : real time and concurrent users.


### Solution
For a novel versioning system with real-time access and multiple users, an Operational Transformation  like ShareDB approach backed by a real-time database is generally the most effective solution. 

OT is specifically built for collaborative editing, ensuring low-latency synchronization, conflict-free merging, and efficient handling of text-based diffs, which is ideal for novel editing.

Using PosgreSQL setup using JSONB as storage for historical versions provides real-time concurrency control with a familiar SQL environment

### How to

1. **`novels`**: Stores main novel metadata and the current content.


```sql
CREATE TABLE novels (
    id SERIAL PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    author VARCHAR(255),
    latest_version JSONB NOT NULL, -- Stores current state of the novel
    latest_version_number INT DEFAULT 1, -- Tracks latest version number
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

```

1. **`novel_versions`**: Stores a reference to the novel’s _id. A diff field representing changes between versions

```sql
CREATE TABLE novel_versions (
    id SERIAL PRIMARY KEY,
    novel_id INT REFERENCES novels(id),
    version_number INT, -- Version number for easy retrieval
    diff JSONB NOT NULL, -- Stores JSONB diff between versions
    created_at TIMESTAMPTZ DEFAULT NOW()
);
```

- Initial Version: The first version of the novel is stored as-is.
- Subsequent Versions: Store only the `diff` between versions to optimize disk space.

- [x] show the novel in its current state

To fetch the latest version of a novel, simply query the novels by id and retrieve the latest_version field.

- [x] show the novel at any point in its history

1. Client requests a specific version by version_number.
2. The service layer retrieves the current content from novels and applies diffs (from novel_versions) to roll back to the requested version.
3. The reconstructed version is sent to the client.

- [x] show the changes made between two versions

1. Retrieve both versions (latest and previous) from the novels and novel_versions tables.
2. If one or both of the versions were stored as diffs, reconstruct the full text by applying diffs up to each target version.

- [x] prioritize disk space efficiency

- Small Changes: Only differences are stored, minimizing redundant data.
- Full Text Only Once: The latest version is stored as full text, with only diffs for historical versions.


- [x] discuss any trade-offs made, as well as potential mitigations

- In a collaborative application with multiple users editing simultaneously can overload PostgreSQL.
> Instead of immediately persisting every operations, we could batch multiple operations together. For example, we could commit every x second or after every 10 operations.

> Using a message queue like RabbitMQ or Kafka, would allows PostgreSQL to handle writes.


- [x] consider any potential domain-specific issues

- if there is frequently requested versions, we need to replay all operations from initial version to the specific version.
> we can optimize with a “read-optimized” table with a version tag (draft, final,...) and full version rebuilt with diffs from initial to this specific version


